{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.inspection import plot_partial_dependence, permutation_importance\n",
    "\n",
    "import autosklearn.classification\n",
    "import autosklearn.metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dataset_all_participants():\n",
    "    \n",
    "    data_test = pd.read_csv('df_SPSS_Final_all_VP_with_recording_problems_removed.csv')\n",
    "    data_test =  data_test.sort_values('VP').reset_index(drop=True)\n",
    "\n",
    "    appended_datapoints = data_test[['VP', 'baseline-eye_0_lhipa', 'baseline-eye_1_lhipa','baseline-HR', 'baseline-HRV', 'baseline-HR_std','baseline-HR_max', 'baseline-HR_min','baseline-Driving_Performance',\n",
    "                           'Nback_LL-eye_0_lhipa','Nback_LL-eye_1_lhipa','Nback_LL-HR', 'Nback_LL-HRV',  'Nback_LL-HR_std','Nback_LL-HR_max', 'Nback_LL-HR_min','Nback_LL-Driving_Performance',\n",
    "                           'Nback_ML-eye_0_lhipa','Nback_ML-eye_1_lhipa', 'Nback_ML-HR','Nback_ML-HRV',  'Nback_ML-HR_std','Nback_ML-HR_max', 'Nback_ML-HR_min','Nback_ML-Driving_Performance',\n",
    "                           'Nback_HL-eye_0_lhipa','Nback_HL-eye_1_lhipa', 'Nback_HL-HR','Nback_HL-HRV',  'Nback_HL-HR_std','Nback_HL-HR_max', 'Nback_HL-HR_min','Nback_HL-Driving_Performance',\n",
    "                           'VIS_LL-eye_0_lhipa','VIS_LL-eye_1_lhipa', 'VIS_LL-HR', 'VIS_LL-HRV', 'VIS_LL-HR_std','VIS_LL-HR_max', 'VIS_LL-HR_min','VIS_LL-Driving_Performance',\n",
    "                           'VIS_ML-eye_0_lhipa','VIS_ML-eye_1_lhipa', 'VIS_ML-HR', 'VIS_ML-HRV', 'VIS_ML-HR_std','VIS_ML-HR_max', 'VIS_ML-HR_min','VIS_ML-Driving_Performance',\n",
    "                           'VIS_HL-eye_0_lhipa','VIS_HL-eye_1_lhipa', 'VIS_HL-HR', 'VIS_HL-HRV', 'VIS_HL-HR_std','VIS_HL-HR_max', 'VIS_HL-HR_min','VIS_HL-Driving_Performance',]]\n",
    "    \n",
    "    ##### Labelling the data ####\n",
    "    \n",
    "    appended_datapoints_with_labels = []\n",
    "    number_of_features_per_class = 8\n",
    "    for i in range((len(appended_datapoints.columns)-1)//number_of_features_per_class):\n",
    "    #         print(i)\n",
    "        df_temp = appended_datapoints.iloc[:, np.r_[0, 1 + (i*number_of_features_per_class) : 1 + ((i+1)*number_of_features_per_class)]].copy()\n",
    "#         print(df_temp)\n",
    "        df_temp['label_task_class'] = appended_datapoints.columns[(i*number_of_features_per_class)+ 2 + 2].split('-')[0]\n",
    "#         print(df_temp)\n",
    "        if i == 0:\n",
    "            df_temp['label_mental_load_level'] = appended_datapoints.columns[(i*number_of_features_per_class)+ 2 + 1].split('-')[0]\n",
    "        else:\n",
    "            df_temp['label_mental_load_level'] = (appended_datapoints.columns[(i*number_of_features_per_class)+ 2 + 2].split('-')[0]).split('_')[1]\n",
    "#         print(df_temp)\n",
    "        df_temp.columns = ['Participant', appended_datapoints.columns[1].split('-')[1],appended_datapoints.columns[2].split('-')[1], \n",
    "                           appended_datapoints.columns[3].split('-')[1],appended_datapoints.columns[4].split('-')[1],\n",
    "                           appended_datapoints.columns[5].split('-')[1],appended_datapoints.columns[6].split('-')[1],\n",
    "                           appended_datapoints.columns[7].split('-')[1],appended_datapoints.columns[8].split('-')[1],\n",
    "                          'label_task_class','label_mental_load_level']\n",
    "#         print(df_temp)    \n",
    "\n",
    "        appended_datapoints_with_labels.append(df_temp)\n",
    "    appended_datapoints_with_labels = pd.concat(appended_datapoints_with_labels)\n",
    "    appended_datapoints_with_labels['label_task_class_factorized'] = pd.factorize(appended_datapoints_with_labels.label_task_class)[0]\n",
    "    appended_datapoints_with_labels['label_mental_load_level_factorized'] = pd.factorize(appended_datapoints_with_labels.label_mental_load_level)[0]\n",
    "    appended_datapoints_with_labels.reset_index(drop=True, inplace = True)\n",
    "    appended_datapoints_with_labels.sort_values(by=['Participant','label_task_class_factorized'], inplace=True)\n",
    "    appended_datapoints_with_labels.reset_index(drop=True, inplace = True)\n",
    "#     appended_datapoints_with_labels.to_csv('df_SPSS_Final_all_with_labels.csv',index =False)\n",
    "    \n",
    "    return appended_datapoints_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_type_to_number_of_classes(classes_type):\n",
    "    if classes_type == 'Mental_load_nback_only':\n",
    "            return 3\n",
    "    elif classes_type == 'Mental_load_and_Sec_task':\n",
    "            return 7\n",
    "    elif classes_type == 'Mental_load_two_levels':\n",
    "            return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset_adjustor(no_classes):\n",
    "\n",
    "    #load dataset and put it in x and y\n",
    "    dataset__ = collect_dataset_all_participants()\n",
    "    if no_classes == 3:\n",
    "        # compare the two levels Nback_LL and Nback_ML (won't work with processed_ll)\n",
    "        dataset__ = dataset__[(dataset__['label_task_class'] == 'Nback_LL') | (dataset__['label_task_class'] == 'Nback_ML') | (dataset__['label_task_class'] == 'Nback_HL')].reset_index(drop=True)\n",
    "        dataset__['label_task_class_factorized'] = pd.factorize(dataset__.label_task_class)[0]\n",
    "        dataset__['label_mental_load_level_factorized'] = pd.factorize(dataset__.label_mental_load_level)[0]\n",
    "        y = dataset__['label_task_class_factorized'].values\n",
    "    \n",
    "    elif no_classes == 7:\n",
    "        y = dataset__['label_task_class_factorized'].values\n",
    "    \n",
    "    elif no_classes == 2:\n",
    "        \n",
    "        # compare the two levels Nback_LL and Nback_ML (won't work with processed_ll)\n",
    "        dataset__ = dataset__[(dataset__['label_task_class'] == 'Nback_LL') | (dataset__['label_task_class'] == 'Nback_ML')].reset_index(drop=True)\n",
    "        dataset__['label_task_class_factorized'] = pd.factorize(dataset__.label_task_class)[0]\n",
    "        dataset__['label_mental_load_level_factorized'] = pd.factorize(dataset__.label_mental_load_level)[0]\n",
    "        y = dataset__['label_task_class_factorized'].values\n",
    "\n",
    "    x = dataset__[['HR','HRV','HR_std','HR_max','HR_min','eye_0_lhipa','eye_1_lhipa','Driving_Performance']].values.astype(float)\n",
    "        \n",
    "    return x , y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_inner_loop_cv(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    print(\"#\"*80)\n",
    "    # print(\"Use predefined accuracy metric\")\n",
    "    cls = autosklearn.classification.AutoSklearnClassifier(\n",
    "        time_left_for_this_task=360,\n",
    "        per_run_time_limit=30,\n",
    "        seed=1514,\n",
    "        metric=autosklearn.metrics.balanced_accuracy,\n",
    "#         ensemble_nbest=1,\n",
    "#         tmp_folder='/tmp/autosklearn_interpretable_models_example_tmp',\n",
    "#         include_estimators=['lda','adaboost','k_nearest_neighbors'],\n",
    "#         include_preprocessors=['no_preprocessing', 'polynomial', 'select_percentile_classification'],\n",
    "#         resampling_strategy='cv',\n",
    "#         resampling_strategy_arguments={'folds': 3},\n",
    "    )\n",
    "    cls.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    train_predictions = cls.predict(X_train)\n",
    "    train_accuracy_per_outer_fold = sklearn.metrics.accuracy_score(y_train, train_predictions)\n",
    "    print(\"Train Accuracy score\", train_accuracy_per_outer_fold)\n",
    "    print(f\"Train Classification report for classifier {cls}:\\n\" f\"{sklearn.metrics.classification_report(y_train, train_predictions)}\\n\")\n",
    "\n",
    "    predictions = cls.predict(X_test)\n",
    "    test_accuracy_per_outer_fold = sklearn.metrics.accuracy_score(y_test, predictions)\n",
    "    print(\"Test Accuracy score\", test_accuracy_per_outer_fold)\n",
    "    print(f\"Test Classification report for classifier {cls}:\\n\" f\"{sklearn.metrics.classification_report(y_test, predictions)}\\n\")\n",
    "    print(\"#\"*80)\n",
    "\n",
    "    print(cls.leaderboard())\n",
    "    print(\"#\"*80)\n",
    "\n",
    "    print(cls.sprint_statistics())\n",
    "    print(\"#\"*80)\n",
    "\n",
    "\n",
    "    features_name = ['HR','HRV','HR_std','HR_max','HR_min','eye_0_lhipa','eye_1_lhipa','Driving_Performance']\n",
    "\n",
    "    print('train permutation importance')\n",
    "\n",
    "    r = permutation_importance(cls, X_train, y_train,\n",
    "                               n_repeats=30,\n",
    "                               random_state=120)\n",
    "\n",
    "    sort_idx = r.importances_mean.argsort()[::-1]\n",
    "    plt.boxplot(r.importances[sort_idx].T, labels=[features_name[i] for i in sort_idx])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    for i in sort_idx[::-1]:\n",
    "        print(f\"{features_name[i]:10s}: {r.importances_mean[i]:.3f} +/- \"\n",
    "              f\"{r.importances_std[i]:.3f}\")\n",
    "\n",
    "    print(\"#\"*80)\n",
    "\n",
    "    print('test permutation importance')\n",
    "\n",
    "    r = permutation_importance(cls, X_test, y_test,\n",
    "                               n_repeats=30,\n",
    "                               random_state=230)\n",
    "\n",
    "    sort_idx = r.importances_mean.argsort()[::-1]\n",
    "    plt.boxplot(r.importances[sort_idx].T, labels=[features_name[i] for i in sort_idx])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    for i in sort_idx[::-1]:\n",
    "        print(f\"{features_name[i]:10s}: {r.importances_mean[i]:.3f} +/- \"\n",
    "              f\"{r.importances_std[i]:.3f}\")\n",
    "\n",
    "    print(\"#\"*80)\n",
    "    \n",
    "    return train_accuracy_per_outer_fold, test_accuracy_per_outer_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "(135, 8) [[78.36956522 11.44072156  0.7330311  ...  1.84444444  1.81231932\n",
      "   0.22411563]\n",
      " [80.67391304 13.95085566  2.04359389 ...  2.22222222  2.33333333\n",
      "   0.19627159]\n",
      " [80.06521739 12.88111319  1.13064379 ...  2.33333333  2.3\n",
      "   0.09948809]\n",
      " ...\n",
      " [93.5        18.73675356  1.99183114 ...  2.12222222  2.03718134\n",
      "   0.21394494]\n",
      " [93.66666667 17.51710128  2.4712911  ...  2.1         2.11111111\n",
      "   0.23378205]\n",
      " [90.80645161 18.25573168  3.7019555  ...  1.86895094  1.87777778\n",
      "   0.72466483]] (135,) [0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0\n",
      " 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1\n",
      " 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2\n",
      " 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "#features options\n",
    "classes_type = 'Mental_load_nback_only' #options: 'Mental_load' for independency from tasks (4 classes) or 'Mental_load_and_Sec_task' for relating to all task levels (7 classes) or 'Mental_load_two_levels' for testing which uses 2 classes 'Nback_ML' and 'Nback_HL'\n",
    "no_classes = class_type_to_number_of_classes(classes_type)\n",
    "k_folds = 5\n",
    "\n",
    "\n",
    "\n",
    "x_all , y_all = Dataset_adjustor(no_classes)\n",
    "# x_all , y_all = shuffle(x_all , y_all)\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds)\n",
    "\n",
    "# Start print\n",
    "print('--------------------------------')\n",
    "print(x_all.shape, x_all , y_all.shape , y_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=========================================-\n",
      "FOLD 0\n",
      "------------\n",
      "[ 27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62\n",
      "  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80\n",
      "  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26]\n",
      "108 27\n",
      "(108, 8) (108,)\n",
      "(27, 8) (27,)\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(x_all, y_all)\n",
    "#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# For fold results\n",
    "train_accuracy_average = []\n",
    "test_accuracy_average = []\n",
    "\n",
    "########### for debugging ##########\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(np.arange(len(x_all)))):\n",
    "    \n",
    "    print('-=========================================-')\n",
    "    print(f'FOLD {fold}')\n",
    "    print('------------')\n",
    "    print(train_ids, test_ids)\n",
    "    print(len(train_ids), len(test_ids))\n",
    "#     print(x_all[test_ids])\n",
    "#     print(y_all[test_ids])\n",
    "    \n",
    "    X_train = x_all[train_ids]\n",
    "    y_train = y_all[train_ids]\n",
    "    \n",
    "    X_test = x_all[test_ids]\n",
    "    y_test = y_all[test_ids]\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    \n",
    "    train_accuracy, test_accuracy = main_inner_loop_cv(X_train, X_test, y_train, y_test)\n",
    "    train_accuracy_average.append(train_accuracy)\n",
    "    test_accuracy_average.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_accuracy_average,test_accuracy_average)\n",
    "print(np.mean(train_accuracy_average), np.mean(test_accuracy_average))\n",
    "print(\"#\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
